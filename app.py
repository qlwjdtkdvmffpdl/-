import streamlit as st
import pandas as pd
import base64
import time
from io import BytesIO

# ë¬¸ì„œ ì²˜ë¦¬ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬
from pypdf import PdfReader
from pptx import Presentation
from docx import Document 

# AI & ê²€ìƒ‰ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬
from langchain_openai import ChatOpenAI
from langchain_community.tools import DuckDuckGoSearchRun
from langchain_core.messages import HumanMessage, SystemMessage

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Ultra AI Analyst Pro", layout="wide", page_icon="ğŸ•µï¸â€â™‚ï¸")

# --- [í•µì‹¬ ìˆ˜ì •] ìŠ¤íƒ€ì¼ ì„¤ì • (ë‹¤í¬ëª¨ë“œ ì™„ë²½ ëŒ€ì‘) ---
st.markdown("""
<style>
    /* 1. ë§í’ì„  ë° ë²„íŠ¼ ë””ìì¸ */
    .stChatMessage {border-radius: 15px; padding: 10px;}
    .stButton>button {width: 100%; border-radius: 5px;}
    
    /* 2. ë¼ë””ì˜¤ ë²„íŠ¼(ëª¨ë“œ ì„ íƒ)ì´ ë“¤ì–´ìˆëŠ” ë°•ìŠ¤ ì „ì²´ë¥¼ í°ìƒ‰ìœ¼ë¡œ */
    div[role="radiogroup"] {
        background-color: #ffffff;
        padding: 15px;
        border-radius: 10px;
        border: 1px solid #ddd;
    }
    
    /* 3. ë¼ë””ì˜¤ ë²„íŠ¼ 'ì•ˆìª½'ì˜ ëª¨ë“  ê¸€ì(píƒœê·¸)ë¥¼ ê²€ì •ìƒ‰ìœ¼ë¡œ ê°•ì œ ê³ ì • (!important) */
    div[role="radiogroup"] p {
        color: #000000 !important;
        font-weight: bold;
    }
    
    /* 4. ë¼ë””ì˜¤ ë²„íŠ¼ ì„ íƒ ì‹œ ì²´í¬ë˜ëŠ” ë™ê·¸ë¼ë¯¸ ìƒ‰ìƒ ì¡°ì • (ì„ íƒ ì‚¬í•­) */
    div[role="radiogroup"] div[data-testid="stMarkdownContainer"] {
        color: #000000 !important;
    }
</style>
""", unsafe_allow_html=True)

# --- í—¬í¼ í•¨ìˆ˜ë“¤ ---
def get_image_base64(file):
    """ì´ë¯¸ì§€ íŒŒì¼ì„ base64 ë¬¸ìì—´ë¡œ ë³€í™˜"""
    img_bytes = file.getvalue()
    return base64.b64encode(img_bytes).decode('utf-8')

def create_word_report(messages):
    """ëŒ€í™” ë‚´ìš©ì„ ì›Œë“œ íŒŒì¼(.docx)ë¡œ ë³€í™˜"""
    doc = Document()
    doc.add_heading('AI ë¶„ì„ ê²°ê³¼ ë³´ê³ ì„œ', 0)
    
    for msg in messages:
        role = "ì‚¬ìš©ì" if msg['role'] == "user" else "AI"
        doc.add_heading(role, level=2)
        doc.add_paragraph(msg['content'])
        doc.add_paragraph("-" * 50)
    
    bio = BytesIO()
    doc.save(bio)
    bio.seek(0)
    return bio

def main():
    # --- ì‚¬ì´ë“œë°”: ì„¤ì • ë° íŒŒì¼ ê´€ë¦¬ ---
    with st.sidebar:
        st.header("âš™ï¸ Pro Control Panel")
        
        # API í‚¤ ê´€ë¦¬
        api_key = None
        try:
            if "OPENAI_API_KEY" in st.secrets:
                api_key = st.secrets["OPENAI_API_KEY"]
        except:
            pass
            
        if not api_key:
            api_key = st.text_input("OpenAI API Key", type="password")

        st.divider()

        # --- í˜ë¥´ì†Œë‚˜(ëª¨ë“œ) ì„ íƒ ---
        st.subheader("ğŸ­ AI ëª¨ë“œ ì„ íƒ (Persona)")
        persona_mode = st.radio(
            "ë¶„ì„ ê´€ì ì„ ì„ íƒí•˜ì„¸ìš”:",
            ["1. ì¹œì ˆí•œ ë¹„ì„œ (ìš”ì•½ & ì„¤ëª…)", 
             "2. ê¹ê¹í•œ ê°ì‚¬ê´€ (ë¶ˆì¼ì¹˜ & ì˜¤ë¥˜ ì ë°œ)", 
             "3. ì°½ì˜ì  ê¸°íšì (ì•„ì´ë””ì–´ ì œì•ˆ)"],
            index=0
        )
        
        # ì•ˆë‚´ ë©”ì‹œì§€
        if "ê°ì‚¬ê´€" in persona_mode:
            st.warning("ğŸš¨ [ê°ì‚¬ ëª¨ë“œ] AIê°€ ë§¤ìš° ë¹„íŒì ìœ¼ë¡œ ë³€í•©ë‹ˆë‹¤.")
        elif "ê¸°íšì" in persona_mode:
            st.success("ğŸ’¡ [ê¸°íš ëª¨ë“œ] ì°½ì˜ì ì¸ ì•„ì´ë””ì–´ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.")
        else:
            st.info("ğŸ˜Š [ë¹„ì„œ ëª¨ë“œ] ì¹œì ˆí•˜ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•©ë‹ˆë‹¤.")

        st.divider()

        # íŒŒì¼ ì—…ë¡œë“œ
        st.subheader("ğŸ“‚ ë¬¸ì„œ ë³´ê´€í•¨")
        uploaded_files = st.file_uploader(
            "íŒŒì¼ì„ ì¶”ê°€í•˜ë©´ ëª©ë¡ì— ìŒ“ì…ë‹ˆë‹¤.", 
            accept_multiple_files=True,
            type=['xlsx', 'csv', 'pdf', 'pptx', 'png', 'jpg', 'jpeg']
        )

        if "file_cache" not in st.session_state:
            st.session_state.file_cache = {} 
        if "processed_file_names" not in st.session_state:
            st.session_state.processed_file_names = []

        if uploaded_files:
            for file in uploaded_files:
                if file.name not in st.session_state.processed_file_names:
                    with st.spinner(f"ğŸ“¥ ìƒˆ íŒŒì¼ ë¶„ì„ ì¤‘... {file.name}"):
                        content = ""
                        images = []
                        ext = file.name.split('.')[-1].lower()
                        
                        try:
                            if ext in ['xlsx', 'csv']:
                                df = pd.read_excel(file) if ext == 'xlsx' else pd.read_csv(file)
                                content = f"[Data: {file.name}]\n{df.to_string()}\n"
                            elif ext == 'pdf':
                                reader = PdfReader(file)
                                content = f"[Doc: {file.name}]\n" + "".join([p.extract_text() for p in reader.pages])
                            elif ext == 'pptx':
                                prs = Presentation(file)
                                txts = []
                                for slide in prs.slides:
                                    txts.extend([s.text for s in slide.shapes if hasattr(s, "text")])
                                content = f"[Slide: {file.name}]\n" + "\n".join(txts)
                            elif ext in ['png', 'jpg', 'jpeg']:
                                b64_img = get_image_base64(file)
                                images.append({
                                    "type": "image_url",
                                    "image_url": {"url": f"data:image/{ext};base64,{b64_img}"}
                                })
                                content = f"[Image File: {file.name}] (ì´ë¯¸ì§€ ë°ì´í„° í¬í•¨ë¨)"

                            st.session_state.file_cache[file.name] = {"text": content, "images": images}
                            st.session_state.processed_file_names.append(file.name)
                            
                        except Exception as e:
                            st.error(f"íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨ ({file.name}): {e}")

        # íŒŒì¼ ì„ íƒ (Context Control)
        st.markdown("ğŸ‘‡ **ì´ë²ˆ ì§ˆë¬¸ì— ì°¸ê³ í•  íŒŒì¼ ì„ íƒ**")
        if st.session_state.file_cache:
            selected_files = st.multiselect(
                "ì²´í¬ëœ íŒŒì¼ë§Œ AIê°€ ì½ìŠµë‹ˆë‹¤.",
                options=list(st.session_state.file_cache.keys()),
                default=list(st.session_state.file_cache.keys())
            )
        else:
            selected_files = []
            st.caption("ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

        st.divider()
        
        # ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ
        st.subheader("ğŸ’¾ ê²°ê³¼ ì €ì¥")
        if st.session_state.get("messages"):
            report_file = create_word_report(st.session_state.messages)
            st.download_button(
                label="ğŸ“ ì›Œë“œ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
                data=report_file,
                file_name="AI_ë¶„ì„_ë³´ê³ ì„œ.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )
            
        if st.button("ğŸ—‘ï¸ ëŒ€í™” ë‚´ìš© ì§€ìš°ê¸°"):
            st.session_state.messages = []
            st.rerun()

    # --- ë©”ì¸ í™”ë©´ ---
    st.title("ğŸ•µï¸â€â™‚ï¸ Ultra Analyst Pro")
    st.caption(f"í˜„ì¬ ëª¨ë“œ: {persona_mode}") 
    
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì—‘ì…€ê³¼ PDF ë‚´ìš©ì„ ë¹„êµí•´ì„œ í‹€ë¦° ë¶€ë¶„ ì°¾ì•„ì¤˜)"):
        if not api_key:
            st.warning("ì™¼ìª½ ì‚¬ì´ë“œë°”ì— OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            st.stop()

        st.chat_message("user").markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            
            # ê²€ìƒ‰ ë¡œì§
            search_result = ""
            search_keywords = ["ê²€ìƒ‰", "ì°¾ì•„", "ì¡°ì‚¬", "ìµœì‹ ", "search", "êµ¬ê¸€ë§"]
            
            if any(keyword in prompt for keyword in search_keywords):
                with st.status("ğŸŒ ì¸í„°ë„·ì—ì„œ ì •ë³´ë¥¼ ì°¾ëŠ” ì¤‘...", expanded=False) as status:
                    try:
                        search_tool = DuckDuckGoSearchRun()
                        search_result = search_tool.run(prompt)
                        status.update(label="âœ… ìµœì‹  ì •ë³´ ê²€ìƒ‰ ì™„ë£Œ!", state="complete")
                    except Exception as e:
                        status.update(label="âš ï¸ ê²€ìƒ‰ ì‹¤íŒ¨ (ì¼ì‹œì  ì˜¤ë¥˜)", state="error")
            
            # ì»¨í…ìŠ¤íŠ¸ ì¡°ë¦½
            context_text = ""
            context_images = []
            
            for fname in selected_files:
                data = st.session_state.file_cache[fname]
                context_text += f"\n--- ë¬¸ì„œ: {fname} ---\n{data['text']}\n"
                if data['images']:
                    context_images.extend(data['images'])

            if search_result:
                context_text += f"\n\n--- [ì¸í„°ë„· ê²€ìƒ‰ ê²°ê³¼] ---\n{search_result}\n"

            try:
                llm = ChatOpenAI(model="gpt-4o", api_key=api_key, temperature=0.1)
                
                content_payload = []
                
                # í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ ì„¤ì •
                if "ì¹œì ˆí•œ ë¹„ì„œ" in persona_mode:
                    system_instruction = """
                    ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ìœ ëŠ¥í•œ ë¹„ì„œì…ë‹ˆë‹¤. 
                    ë¬¸ì„œì˜ ë‚´ìš©ì„ ì´í•´í•˜ê¸° ì‰½ê²Œ ìš”ì•½í•˜ê³ , ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë¶€ë“œëŸ¬ìš´ í†¤ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
                    ë³µì¡í•œ ë°ì´í„°ëŠ” í‘œë¡œ ì •ë¦¬í•´ì£¼ê³ , ì´ˆë³´ìë„ ì•Œê¸° ì‰½ê²Œ ì„¤ëª…í•˜ì„¸ìš”.
                    """
                elif "ê¹ê¹í•œ ê°ì‚¬ê´€" in persona_mode:
                    system_instruction = """
                    ë‹¹ì‹ ì€ ëƒ‰ì² í•œ 'í’ˆì§ˆ ê´€ë¦¬ ê°ì‚¬ê´€(Auditor)'ì…ë‹ˆë‹¤.
                    ë‹¹ì‹ ì˜ ëª©í‘œëŠ” ì¹­ì°¬ì´ ì•„ë‹ˆë¼ **'ì˜¤ë¥˜ì™€ ë¶ˆì¼ì¹˜ ë°œê²¬'**ì…ë‹ˆë‹¤.
                    ì œê³µëœ ë¬¸ì„œë“¤(ì—‘ì…€, PDF ë“±) ê°„ì— ë°ì´í„°ê°€ ë‹¤ë¥´ê±°ë‚˜, ê³„ì‚°ì´ í‹€ë¦° ë¶€ë¶„ì´ ìˆë‹¤ë©´
                    ë°˜ë“œì‹œ ë¹¨ê°„ìƒ‰ ê¸€ì”¨ë‚˜ ë³¼ë“œì²´(**Bold**)ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°•ë ¥í•˜ê²Œ ê²½ê³ í•˜ì„¸ìš”.
                    ë§íˆ¬ëŠ” ì§ì„¤ì ì´ê³  ë‹¨í˜¸í•˜ê²Œ í•˜ì„¸ìš”. "í™•ì¸ ë¶€íƒë“œë¦½ë‹ˆë‹¤" ëŒ€ì‹  "ì˜¤ë¥˜ì…ë‹ˆë‹¤"ë¼ê³  í•˜ì„¸ìš”.
                    """
                elif "ì°½ì˜ì  ê¸°íšì" in persona_mode:
                    system_instruction = """
                    ë‹¹ì‹ ì€ ì•„ì´ë””ì–´ê°€ ë„˜ì¹˜ëŠ” 'ë§ˆì¼€íŒ… ê¸°íšì'ì…ë‹ˆë‹¤.
                    ë¬¸ì„œì˜ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìˆ¨ê²¨ì§„ ì¸ì‚¬ì´íŠ¸ë¥¼ ì°¾ê³ , ìƒˆë¡œìš´ ì‚¬ì—… ê¸°íšŒë‚˜ ê°œì„  ì•„ì´ë””ì–´ë¥¼ ì œì•ˆí•˜ì„¸ìš”.
                    ì´ëª¨ì§€(ğŸ’¡, ğŸš€)ë¥¼ ì ê·¹ì ìœ¼ë¡œ ì‚¬ìš©í•˜ê³ , ì—´ì •ì ì´ê³  ê¸ì •ì ì¸ í†¤ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
                    """
                else:
                    system_instruction = "ë‹¹ì‹ ì€ ìœ ëŠ¥í•œ AI ë¶„ì„ê°€ì…ë‹ˆë‹¤."

                final_system_prompt = f"""
                {system_instruction}
                
                [ì°¸ê³  ë¬¸ì„œ ë° ë°ì´í„°]
                {context_text if context_text else "(ì°¸ê³ í•  ë¬¸ì„œ ì—†ìŒ)"}
                """
                
                content_payload.append(SystemMessage(content=final_system_prompt))
                
                if context_images:
                    content_payload.extend([HumanMessage(content=[img]) for img in context_images])
                
                # ê¸°ì–µë ¥
                for msg in st.session_state.messages[-5:]: 
                    if msg['role'] == 'user':
                        pass 
                    else:
                        content_payload.append(HumanMessage(content=msg['content']))

                content_payload.append(HumanMessage(content=prompt))

                response = llm.invoke(content_payload)
                full_response = response.content
                
                message_placeholder.markdown(full_response)
                st.session_state.messages.append({"role": "assistant", "content": full_response})

            except Exception as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

if __name__ == "__main__":
    main()
