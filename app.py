import streamlit as st
import pandas as pd
import base64
import time
from pypdf import PdfReader
from pptx import Presentation
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage

# í˜ì´ì§€ ì„¤ì • (ë„“ì€ í™”ë©´ ì‚¬ìš©)
st.set_page_config(page_title="Ultra AI Analyst", layout="wide", page_icon="âš¡")

# --- CSS ìŠ¤íƒ€ì¼ (ë§í’ì„ , í—¤ë” ë“± ì´ì˜ê²Œ ê¾¸ë¯¸ê¸°) ---
st.markdown("""
<style>
    .stChatMessage {border-radius: 20px; padding: 10px;}
    .stHeader {background-color: transparent;}
</style>
""", unsafe_allow_html=True)

def get_image_base64(file):
    """ì´ë¯¸ì§€ íŒŒì¼ì„ base64ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜"""
    img_bytes = file.getvalue()
    return base64.b64encode(img_bytes).decode('utf-8')

def main():
    # ì‚¬ì´ë“œë°”: ì„¤ì • ë° íŒŒì¼ ì—…ë¡œë“œ
    with st.sidebar:
        st.header("âš™ï¸ Control Panel")
        # ì‹œì—°ìš© API í‚¤ ê³ ì • (ì—¬ê¸°ì— í‚¤ë¥¼ ë„£ìœ¼ë©´ ì…ë ¥ì°½ ì‚¬ë¼ì§)
        api_key = st.text_input("OpenAI API Key", type="password")
        
        st.divider()
        st.subheader("ğŸ“‚ ìë£Œ ì—…ë¡œë“œ")
        uploaded_files = st.file_uploader(
            "ì—‘ì…€, PDF, PPT, ì‚¬ì§„ì„ ëª¨ë‘ ì˜¬ë ¤ì£¼ì„¸ìš”.", 
            accept_multiple_files=True,
            type=['xlsx', 'csv', 'pdf', 'pptx', 'png', 'jpg', 'jpeg']
        )
        
        if st.button("ğŸ”„ ëŒ€í™” ë‚´ìš© ì´ˆê¸°í™”"):
            st.session_state.messages = []
            st.session_state.context_data = ""
            st.rerun()

    # ë©”ì¸ íƒ€ì´í‹€
    st.title("âš¡ Ultra Multi-Modal AI Agent")
    st.caption("ğŸš€ ì—‘ì…€ + PDF + PPT + ì´ë¯¸ì§€ í†µí•© ë¶„ì„ ì‹œìŠ¤í…œ")
    st.divider()

    # --- Session State ì´ˆê¸°í™” (ëŒ€í™” ê¸°ì–µì¥ì¹˜) ---
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "context_data" not in st.session_state:
        st.session_state.context_data = ""
    if "processed_files" not in st.session_state:
        st.session_state.processed_files = []

    # 1. íŒŒì¼ ì²˜ë¦¬ ë¡œì§ (íŒŒì¼ì´ ì˜¬ë¼ì˜¤ë©´ ë”± í•œ ë²ˆë§Œ ì‹¤í–‰)
    if uploaded_files and sorted([f.name for f in uploaded_files]) != sorted(st.session_state.processed_files):
        # (3ë²ˆ ê¸°ëŠ¥) ìˆì–´ ë³´ì´ëŠ” ë¡œë”© ì• ë‹ˆë©”ì´ì…˜
        with st.status("ğŸ” ë¬¸ì„œë¥¼ ìŠ¤ìº”í•˜ê³  ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ëŠ” ì¤‘...", expanded=True) as status:
            
            raw_text = ""
            image_contents = []
            
            for file in uploaded_files:
                ext = file.name.split('.')[-1].lower()
                time.sleep(0.5) # ì‹œì—°ìš© ë”œë ˆì´ (ë„ˆë¬´ ë¹ ë¥´ë©´ ì¬ë¯¸ì—†ìŒ)
                
                # ì—‘ì…€ ì²˜ë¦¬ + (2ë²ˆ ê¸°ëŠ¥) ë°ì´í„° ì‹œê°í™” ìë™ ìƒì„±
                if ext in ['xlsx', 'csv']:
                    st.write(f"ğŸ“Š ì—‘ì…€ ë°ì´í„° ë¶„ì„ ì¤‘: {file.name}")
                    df = pd.read_excel(file) if ext == 'xlsx' else pd.read_csv(file)
                    raw_text += f"\n[Excel Data: {file.name}]\n{df.to_string()}\n"
                    
                    # ì—‘ì…€ì´ ìˆìœ¼ë©´ ì‚¬ì´ë“œë°”ë‚˜ ìƒë‹¨ì— ì°¨íŠ¸ ë°”ë¡œ ê·¸ë ¤ë²„ë¦¬ê¸°
                    with st.expander(f"ğŸ“ˆ {file.name} - ë°ì´í„° ìë™ ì‹œê°í™” (Click to Open)", expanded=False):
                        st.dataframe(df.head())
                        # ìˆ«ì ë°ì´í„°ë§Œ ë½‘ì•„ì„œ ì°¨íŠ¸ ê·¸ë¦¬ê¸°
                        numeric_df = df.select_dtypes(include=['float64', 'int64'])
                        if not numeric_df.empty:
                            st.line_chart(numeric_df)
                            st.info("AIê°€ ìˆ«ì ë°ì´í„°ë¥¼ ê°ì§€í•˜ì—¬ ìë™ìœ¼ë¡œ íŠ¸ë Œë“œ ì°¨íŠ¸ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")

                # PDF ì²˜ë¦¬
                elif ext == 'pdf':
                    st.write(f"ğŸ“„ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘: {file.name}")
                    reader = PdfReader(file)
                    text = "".join([page.extract_text() for page in reader.pages])
                    raw_text += f"\n[PDF Document: {file.name}]\n{text}\n"

                # PPT ì²˜ë¦¬
                elif ext == 'pptx':
                    st.write(f"ğŸ“¢ í”„ë ˆì  í…Œì´ì…˜ ë¶„ì„ ì¤‘: {file.name}")
                    prs = Presentation(file)
                    ppt_text = ""
                    for i, slide in enumerate(prs.slides):
                        txts = [shape.text for shape in slide.shapes if hasattr(shape, "text")]
                        ppt_text += f"Slide {i+1}: {' '.join(txts)}\n"
                    raw_text += f"\n[PPT Slides: {file.name}]\n{ppt_text}\n"

                # ì´ë¯¸ì§€ ì²˜ë¦¬
                elif ext in ['png', 'jpg', 'jpeg']:
                    st.write(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¹„ì „ ì¸ì‹ ì¤‘: {file.name}")
                    b64_img = get_image_base64(file)
                    image_contents.append({
                        "type": "image_url",
                        "image_url": {"url": f"data:image/{ext};base64,{b64_img}"}
                    })

            # í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ì •ë³´ë¥¼ ì„¸ì…˜ì— ì €ì¥
            st.session_state.context_data = {"text": raw_text, "images": image_contents}
            st.session_state.processed_files = [f.name for f in uploaded_files]
            
            status.update(label="âœ… ëª¨ë“  ë¬¸ì„œ ë¶„ì„ ì™„ë£Œ! AIê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.", state="complete", expanded=False)

    # 2. (1ë²ˆ ê¸°ëŠ¥) ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„
    # ì´ì „ ëŒ€í™” ê¸°ë¡ í‘œì‹œ
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # ì‚¬ìš©ì ì…ë ¥ ëŒ€ê¸°
    if prompt := st.chat_input("ë¬¸ì„œì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš” (ì˜ˆ: ì´ ì—‘ì…€ì˜ ë§¤ì¶œ ì¶”ì´ì™€ ë³´ê³ ì„œ ë‚´ìš©ì„ ë¹„êµí•´ì¤˜)"):
        if not api_key:
            st.error("API í‚¤ë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”!")
            st.stop()
            
        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        st.chat_message("user").markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

        # AI ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            # (3ë²ˆ ê¸°ëŠ¥) ë‹µë³€ ìƒì„± ì¤‘ ë¡œë”© íš¨ê³¼
            message_placeholder = st.empty()
            with st.spinner("AIê°€ ë¬¸ì„œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒê° ì¤‘ì…ë‹ˆë‹¤..."):
                
                try:
                    llm = ChatOpenAI(model="gpt-4o", api_key=api_key, temperature=0.1)
                    
                    # LLMì— ë³´ë‚¼ ë©”ì‹œì§€ êµ¬ì„±
                    content_payload = []
                    
                    # 1. í…ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
                    if st.session_state.context_data.get("text"):
                        content_payload.append({
                            "type": "text", 
                            "text": f"ë‹¤ìŒì€ ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ ë¬¸ì„œë“¤ì˜ ë‚´ìš©ì…ë‹ˆë‹¤. ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”:\n{st.session_state.context_data['text']}"
                        })
                    
                    # 2. ì´ë¯¸ì§€ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
                    if st.session_state.context_data.get("images"):
                        content_payload.extend(st.session_state.context_data['images'])
                        
                    # 3. ì‚¬ìš©ì ì§ˆë¬¸ ì¶”ê°€
                    content_payload.append({
                        "type": "text",
                        "text": prompt
                    })
                    
                    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (í˜ë¥´ì†Œë‚˜ ì„¤ì •)
                    system_msg = SystemMessage(content="""
                        ë‹¹ì‹ ì€ íƒì›”í•œ ë°ì´í„° ë¶„ì„ê°€ì´ì ë¹„ì¦ˆë‹ˆìŠ¤ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. 
                        ì œê³µëœ ì—‘ì…€, PDF, PPT, ì´ë¯¸ì§€ ìë£Œë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ í†µì°°ë ¥ ìˆëŠ” ë‹µë³€ì„ ì£¼ì„¸ìš”.
                        ë‹µë³€í•  ë•ŒëŠ” ì¤‘ìš”í•œ ìˆ«ìì— ë³¼ë“œì²´ë¥¼ ì‚¬ìš©í•˜ê³ , í•„ìš”í•˜ë‹¤ë©´ ë§ˆí¬ë‹¤ìš´ í‘œë¥¼ ê·¸ë ¤ì„œ ê°€ë…ì„±ì„ ë†’ì´ì„¸ìš”.
                        í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.
                    """)
                    
                    human_msg = HumanMessage(content=content_payload)
                    
                    # ìŠ¤íŠ¸ë¦¬ë° íš¨ê³¼ (íƒ€ì ì¹˜ë“¯ ë‚˜ì˜¤ëŠ” íš¨ê³¼)
                    full_response = ""
                    response = llm.stream([system_msg, human_msg])
                    
                    for chunk in response:
                        if chunk.content:
                            full_response += chunk.content
                            message_placeholder.markdown(full_response + "â–Œ")
                    
                    message_placeholder.markdown(full_response)
                    
                    # ëŒ€í™” ê¸°ë¡ì— ì €ì¥
                    st.session_state.messages.append({"role": "assistant", "content": full_response})

                except Exception as e:
                    st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

if __name__ == "__main__":
    main()